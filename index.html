<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>courserapml by zaep</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">courserapml</h1>
      <h2 class="project-tagline"></h2>
      <a href="https://github.com/zaep/courseraPML" class="btn">View on GitHub</a>
      <a href="https://github.com/zaep/courseraPML/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/zaep/courseraPML/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h2>
<a id="loading-the-data" class="anchor" href="#loading-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Loading the data</h2>

<p>The following code loads the training and testing datasets into R:</p>

<div class="highlight highlight-r"><pre><span class="pl-smi">pml_train</span> <span class="pl-k">&lt;-</span> read.csv(<span class="pl-s"><span class="pl-pds">"</span>https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv<span class="pl-pds">"</span></span>)
<span class="pl-smi">pml_test</span> <span class="pl-k">&lt;-</span> read.csv(<span class="pl-s"><span class="pl-pds">"</span>https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv<span class="pl-pds">"</span></span>)</pre></div>

<h2>
<a id="splitting-the-data" class="anchor" href="#splitting-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Splitting the data</h2>

<p>We set a seed value to make the data partitioning reproducible.</p>

<div class="highlight highlight-r"><pre>str(<span class="pl-smi">pml_train</span>)</pre></div>

<pre><code>## 'data.frame':    19622 obs. of  160 variables:
##  $ X                       : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ user_name               : Factor w/ 6 levels "adelmo","carlitos",..: 2 2 2 2 2 2 2 2 2 2 ...
##  $ raw_timestamp_part_1    : int  1323084231 1323084231 1323084231 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 ...
##  $ raw_timestamp_part_2    : int  788290 808298 820366 120339 196328 304277 368296 440390 484323 484434 ...
##  $ cvtd_timestamp          : Factor w/ 20 levels "02/12/2011 13:32",..: 9 9 9 9 9 9 9 9 9 9 ...
##  $ new_window              : Factor w/ 2 levels "no","yes": 1 1 1 1 1 1 1 1 1 1 ...
##  $ num_window              : int  11 11 11 12 12 12 12 12 12 12 ...
##  $ roll_belt               : num  1.41 1.41 1.42 1.48 1.48 1.45 1.42 1.42 1.43 1.45 ...
##  $ pitch_belt              : num  8.07 8.07 8.07 8.05 8.07 8.06 8.09 8.13 8.16 8.17 ...
##  $ yaw_belt                : num  -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 ...
##  $ total_accel_belt        : int  3 3 3 3 3 3 3 3 3 3 ...
##  $ kurtosis_roll_belt      : Factor w/ 397 levels "","-0.016850",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_picth_belt     : Factor w/ 317 levels "","-0.021887",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_yaw_belt       : Factor w/ 2 levels "","#DIV/0!": 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_belt      : Factor w/ 395 levels "","-0.003095",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_belt.1    : Factor w/ 338 levels "","-0.005928",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_yaw_belt       : Factor w/ 2 levels "","#DIV/0!": 1 1 1 1 1 1 1 1 1 1 ...
##  $ max_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_belt          : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_belt            : Factor w/ 68 levels "","-0.1","-0.2",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ min_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_belt          : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_belt            : Factor w/ 68 levels "","-0.1","-0.2",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ amplitude_roll_belt     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_pitch_belt    : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_yaw_belt      : Factor w/ 4 levels "","#DIV/0!","0.00",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ var_total_accel_belt    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_roll_belt        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_pitch_belt          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_pitch_belt       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_pitch_belt          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_yaw_belt         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ gyros_belt_x            : num  0 0.02 0 0.02 0.02 0.02 0.02 0.02 0.02 0.03 ...
##  $ gyros_belt_y            : num  0 0 0 0 0.02 0 0 0 0 0 ...
##  $ gyros_belt_z            : num  -0.02 -0.02 -0.02 -0.03 -0.02 -0.02 -0.02 -0.02 -0.02 0 ...
##  $ accel_belt_x            : int  -21 -22 -20 -22 -21 -21 -22 -22 -20 -21 ...
##  $ accel_belt_y            : int  4 4 5 3 2 4 3 4 2 4 ...
##  $ accel_belt_z            : int  22 22 23 21 24 21 21 21 24 22 ...
##  $ magnet_belt_x           : int  -3 -7 -2 -6 -6 0 -4 -2 1 -3 ...
##  $ magnet_belt_y           : int  599 608 600 604 600 603 599 603 602 609 ...
##  $ magnet_belt_z           : int  -313 -311 -305 -310 -302 -312 -311 -313 -312 -308 ...
##  $ roll_arm                : num  -128 -128 -128 -128 -128 -128 -128 -128 -128 -128 ...
##  $ pitch_arm               : num  22.5 22.5 22.5 22.1 22.1 22 21.9 21.8 21.7 21.6 ...
##  $ yaw_arm                 : num  -161 -161 -161 -161 -161 -161 -161 -161 -161 -161 ...
##  $ total_accel_arm         : int  34 34 34 34 34 34 34 34 34 34 ...
##  $ var_accel_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_roll_arm         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_pitch_arm        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_yaw_arm             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_yaw_arm          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_yaw_arm             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ gyros_arm_x             : num  0 0.02 0.02 0.02 0 0.02 0 0.02 0.02 0.02 ...
##  $ gyros_arm_y             : num  0 -0.02 -0.02 -0.03 -0.03 -0.03 -0.03 -0.02 -0.03 -0.03 ...
##  $ gyros_arm_z             : num  -0.02 -0.02 -0.02 0.02 0 0 0 0 -0.02 -0.02 ...
##  $ accel_arm_x             : int  -288 -290 -289 -289 -289 -289 -289 -289 -288 -288 ...
##  $ accel_arm_y             : int  109 110 110 111 111 111 111 111 109 110 ...
##  $ accel_arm_z             : int  -123 -125 -126 -123 -123 -122 -125 -124 -122 -124 ...
##  $ magnet_arm_x            : int  -368 -369 -368 -372 -374 -369 -373 -372 -369 -376 ...
##  $ magnet_arm_y            : int  337 337 344 344 337 342 336 338 341 334 ...
##  $ magnet_arm_z            : int  516 513 513 512 506 513 509 510 518 516 ...
##  $ kurtosis_roll_arm       : Factor w/ 330 levels "","-0.02438",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_picth_arm      : Factor w/ 328 levels "","-0.00484",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_yaw_arm        : Factor w/ 395 levels "","-0.01548",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_arm       : Factor w/ 331 levels "","-0.00051",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_pitch_arm      : Factor w/ 328 levels "","-0.00184",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_yaw_arm        : Factor w/ 395 levels "","-0.00311",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ max_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_arm             : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_arm             : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_roll_arm      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_pitch_arm     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_yaw_arm       : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ roll_dumbbell           : num  13.1 13.1 12.9 13.4 13.4 ...
##  $ pitch_dumbbell          : num  -70.5 -70.6 -70.3 -70.4 -70.4 ...
##  $ yaw_dumbbell            : num  -84.9 -84.7 -85.1 -84.9 -84.9 ...
##  $ kurtosis_roll_dumbbell  : Factor w/ 398 levels "","-0.0035","-0.0073",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_picth_dumbbell : Factor w/ 401 levels "","-0.0163","-0.0233",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_yaw_dumbbell   : Factor w/ 2 levels "","#DIV/0!": 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_dumbbell  : Factor w/ 401 levels "","-0.0082","-0.0096",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_pitch_dumbbell : Factor w/ 402 levels "","-0.0053","-0.0084",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_yaw_dumbbell   : Factor w/ 2 levels "","#DIV/0!": 1 1 1 1 1 1 1 1 1 1 ...
##  $ max_roll_dumbbell       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_dumbbell      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_dumbbell        : Factor w/ 73 levels "","-0.1","-0.2",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ min_roll_dumbbell       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_dumbbell      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_dumbbell        : Factor w/ 73 levels "","-0.1","-0.2",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ amplitude_roll_dumbbell : num  NA NA NA NA NA NA NA NA NA NA ...
##   [list output truncated]
</code></pre>

<div class="highlight highlight-r"><pre>library(<span class="pl-smi">caret</span>)

set.seed(<span class="pl-c1">126377</span>)
<span class="pl-smi">train_idx</span> <span class="pl-k">&lt;-</span> createDataPartition(<span class="pl-smi">pml_train</span><span class="pl-k">$</span><span class="pl-smi">classe</span>, <span class="pl-v">p</span> <span class="pl-k">=</span> .<span class="pl-c1">6</span>, <span class="pl-v">list</span> <span class="pl-k">=</span> <span class="pl-c1">FALSE</span>)

<span class="pl-smi">training</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">pml_train</span>[<span class="pl-smi">train_idx</span>, ]
<span class="pl-smi">testing</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">pml_train</span>[<span class="pl-k">-</span><span class="pl-smi">train_idx</span>, ]</pre></div>

<h2>
<a id="exploratory-data-analysis" class="anchor" href="#exploratory-data-analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Exploratory Data Analysis</h2>

<div class="highlight highlight-r"><pre>str(<span class="pl-smi">training</span>[, sapply(<span class="pl-smi">training</span>, <span class="pl-smi">is.factor</span>)])</pre></div>

<pre><code>## 'data.frame':    11776 obs. of  37 variables:
##  $ user_name              : Factor w/ 6 levels "adelmo","carlitos",..: 2 2 2 2 2 2 2 2 2 2 ...
##  $ cvtd_timestamp         : Factor w/ 20 levels "02/12/2011 13:32",..: 9 9 9 9 9 9 9 9 9 9 ...
##  $ new_window             : Factor w/ 2 levels "no","yes": 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_roll_belt     : Factor w/ 397 levels "","-0.016850",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_picth_belt    : Factor w/ 317 levels "","-0.021887",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_yaw_belt      : Factor w/ 2 levels "","#DIV/0!": 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_belt     : Factor w/ 395 levels "","-0.003095",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_belt.1   : Factor w/ 338 levels "","-0.005928",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_yaw_belt      : Factor w/ 2 levels "","#DIV/0!": 1 1 1 1 1 1 1 1 1 1 ...
##  $ max_yaw_belt           : Factor w/ 68 levels "","-0.1","-0.2",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ min_yaw_belt           : Factor w/ 68 levels "","-0.1","-0.2",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ amplitude_yaw_belt     : Factor w/ 4 levels "","#DIV/0!","0.00",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_roll_arm      : Factor w/ 330 levels "","-0.02438",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_picth_arm     : Factor w/ 328 levels "","-0.00484",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_yaw_arm       : Factor w/ 395 levels "","-0.01548",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_arm      : Factor w/ 331 levels "","-0.00051",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_pitch_arm     : Factor w/ 328 levels "","-0.00184",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_yaw_arm       : Factor w/ 395 levels "","-0.00311",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_roll_dumbbell : Factor w/ 398 levels "","-0.0035","-0.0073",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_picth_dumbbell: Factor w/ 401 levels "","-0.0163","-0.0233",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_yaw_dumbbell  : Factor w/ 2 levels "","#DIV/0!": 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_dumbbell : Factor w/ 401 levels "","-0.0082","-0.0096",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_pitch_dumbbell: Factor w/ 402 levels "","-0.0053","-0.0084",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_yaw_dumbbell  : Factor w/ 2 levels "","#DIV/0!": 1 1 1 1 1 1 1 1 1 1 ...
##  $ max_yaw_dumbbell       : Factor w/ 73 levels "","-0.1","-0.2",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ min_yaw_dumbbell       : Factor w/ 73 levels "","-0.1","-0.2",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ amplitude_yaw_dumbbell : Factor w/ 3 levels "","#DIV/0!","0.00": 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_roll_forearm  : Factor w/ 322 levels "","-0.0227","-0.0359",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_picth_forearm : Factor w/ 323 levels "","-0.0073","-0.0442",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_yaw_forearm   : Factor w/ 2 levels "","#DIV/0!": 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_forearm  : Factor w/ 323 levels "","-0.0004","-0.0013",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_pitch_forearm : Factor w/ 319 levels "","-0.0113","-0.0131",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_yaw_forearm   : Factor w/ 2 levels "","#DIV/0!": 1 1 1 1 1 1 1 1 1 1 ...
##  $ max_yaw_forearm        : Factor w/ 45 levels "","-0.1","-0.2",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ min_yaw_forearm        : Factor w/ 45 levels "","-0.1","-0.2",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ amplitude_yaw_forearm  : Factor w/ 3 levels "","#DIV/0!","0.00": 1 1 1 1 1 1 1 1 1 1 ...
##  $ classe                 : Factor w/ 5 levels "A","B","C","D",..: 1 1 1 1 1 1 1 1 1 1 ...
</code></pre>

<p>There are several factor variables in the dataset. However, it seems like some of them should really be numeric, since they have many levels. Some algorithms can not handle factors with more than 32 levels (e.g. <code>tree::tree()</code>). Hence, all factor variables with more than 32 levels are transformed into numerical variables. In addition, the <code>user_name</code> variable should be a character variable (although there are only 6 user names in the training set, the set of all possible user names might be large), while <code>cvtd_timestamp</code> should be a datetime format.</p>

<p>We create a function for factor transformation, so the same transformations can later be easily applied to the test dataset.</p>

<div class="highlight highlight-r"><pre><span class="pl-en">transformFactors</span> <span class="pl-k">&lt;-</span> <span class="pl-k">function</span>(<span class="pl-smi">data</span>) {
  <span class="pl-smi">cols</span> <span class="pl-k">&lt;-</span> sapply(<span class="pl-smi">data</span>, <span class="pl-smi">is.factor</span>) <span class="pl-k">&amp;</span> grepl(<span class="pl-s"><span class="pl-pds">"</span>skewness|kurtosis|yaw<span class="pl-pds">"</span></span>, names(<span class="pl-smi">data</span>))
  <span class="pl-smi">data</span>[, <span class="pl-smi">cols</span>] <span class="pl-k">&lt;-</span> as.numeric(as.character(<span class="pl-smi">data</span>[, <span class="pl-smi">cols</span>]))
  <span class="pl-smi">data</span><span class="pl-k">$</span><span class="pl-smi">user_name</span> <span class="pl-k">&lt;-</span> as.character(<span class="pl-smi">data</span><span class="pl-k">$</span><span class="pl-smi">user_name</span>)
  <span class="pl-smi">data</span><span class="pl-k">$</span><span class="pl-smi">cvtd_timestamp</span> <span class="pl-k">&lt;-</span> <span class="pl-e">lubridate</span><span class="pl-k">::</span>parse_date_time(<span class="pl-smi">data</span><span class="pl-k">$</span><span class="pl-smi">cvtd_timestamp</span>, <span class="pl-s"><span class="pl-pds">"</span>d/m/Y H:M<span class="pl-pds">"</span></span>)
  <span class="pl-k">return</span>(<span class="pl-smi">data</span>)
}

<span class="pl-smi">training</span> <span class="pl-k">&lt;-</span> transformFactors(<span class="pl-smi">training</span>)</pre></div>

<pre><code>## Warning in transformFactors(training): NAs introduced by coercion
</code></pre>

<div class="highlight highlight-r"><pre>str(<span class="pl-smi">training</span>[, sapply(<span class="pl-smi">training</span>, <span class="pl-smi">is.factor</span>)])</pre></div>

<pre><code>## 'data.frame':    11776 obs. of  2 variables:
##  $ new_window: Factor w/ 2 levels "no","yes": 1 1 1 1 1 1 1 1 1 1 ...
##  $ classe    : Factor w/ 5 levels "A","B","C","D",..: 1 1 1 1 1 1 1 1 1 1 ...
</code></pre>

<p>In order to visualize the dataset in two dimensional space, we perform <em>Principal Component Analysis</em> (PCA). Before PCA can be applied, we need to:</p>

<ul>
<li>Remove variables with zero variance (<code>caret::nearZeroVar</code> is used to identify such variables)</li>
<li>Remove non-numerical variables</li>
<li>Center and Scale variables</li>
</ul>

<p>The first two principal components capture most of the variance in the dataset.</p>

<div class="highlight highlight-r"><pre><span class="pl-c"># identify zero variance variables</span>
<span class="pl-smi">nzv</span> <span class="pl-k">&lt;-</span> nearZeroVar(<span class="pl-smi">training</span>, <span class="pl-v">saveMetrics</span> <span class="pl-k">=</span> <span class="pl-c1">TRUE</span>)
<span class="pl-c">#remove zero variance and non-numeric variables</span>
<span class="pl-smi">train_num</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">training</span>[, <span class="pl-k">!</span><span class="pl-smi">nzv</span><span class="pl-k">$</span><span class="pl-smi">zeroVar</span> <span class="pl-k">&amp;</span> sapply(<span class="pl-smi">training</span>, <span class="pl-smi">is.numeric</span>)]
<span class="pl-c"># scale and center, then perform PCA</span>
<span class="pl-smi">pca_train</span> <span class="pl-k">&lt;-</span> prcomp(<span class="pl-smi">train_num</span>[complete.cases(<span class="pl-smi">train_num</span>), <span class="pl-k">-</span><span class="pl-c1">1</span>],
                     <span class="pl-v">center</span> <span class="pl-k">=</span> <span class="pl-c1">TRUE</span>,
                     <span class="pl-v">scale.</span> <span class="pl-k">=</span> <span class="pl-c1">TRUE</span>)
plot(<span class="pl-smi">pca_train</span>)</pre></div>

<p><img src="figure/edaPCA-1.png" alt="plot of chunk edaPCA"> </p>

<p>Next, we plot the first two principal components and use the <code>classe</code> variable to color the observations. The plot indicates that the observations fall into 3-4 clusters. However, those cluster do not separate the <code>classe</code> variable values very well.</p>

<div class="highlight highlight-r"><pre>library(<span class="pl-smi">ggplot2</span>)
library(<span class="pl-smi">scales</span>)

<span class="pl-smi">idxs</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">train_num</span>[complete.cases(<span class="pl-smi">train_num</span>), <span class="pl-s"><span class="pl-pds">"</span>X<span class="pl-pds">"</span></span>]

ggplot(<span class="pl-k">data.frame</span>(<span class="pl-v">pc1</span> <span class="pl-k">=</span> <span class="pl-smi">pca_train</span><span class="pl-k">$</span><span class="pl-smi">x</span>[, <span class="pl-c1">1</span>], 
                  <span class="pl-v">pc2</span> <span class="pl-k">=</span> <span class="pl-smi">pca_train</span><span class="pl-k">$</span><span class="pl-smi">x</span>[, <span class="pl-c1">2</span>], 
                  <span class="pl-v">classe</span> <span class="pl-k">=</span> <span class="pl-smi">training</span>[<span class="pl-smi">training</span><span class="pl-k">$</span><span class="pl-smi">X</span> <span class="pl-k">%in%</span> <span class="pl-smi">idxs</span>, <span class="pl-s"><span class="pl-pds">"</span>classe<span class="pl-pds">"</span></span>]), 
       aes(<span class="pl-smi">pc1</span>, <span class="pl-smi">pc2</span>)) <span class="pl-k">+</span> 
  geom_point(aes(<span class="pl-v">color</span> <span class="pl-k">=</span> <span class="pl-smi">classe</span>), <span class="pl-v">size</span> <span class="pl-k">=</span> <span class="pl-c1">3</span>) <span class="pl-k">+</span>
  ggtitle(<span class="pl-s"><span class="pl-pds">"</span>First 2 principal components of the WLE dataset<span class="pl-pds">"</span></span>)</pre></div>

<p><img src="figure/edaPCAPlot-1.png" alt="plot of chunk edaPCAPlot"> </p>

<h2>
<a id="data-preprocessing" class="anchor" href="#data-preprocessing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Preprocessing</h2>

<p>We remove variables which</p>

<ul>
<li>have 0 variance</li>
<li>have <code>NA</code> values in it</li>
<li>identify individual rows (index variable <code>X</code>) or study participants (<code>user_name</code>), </li>
<li>are timestamps (<code>cvtd_timestamp</code>, <code>raw_timestamp_part_1</code>, <code>raw_timestamp_part_2</code>), </li>
<li>and time window indicators (<code>num_window</code>, <code>new_window</code>).</li>
</ul>

<p>This gives us the <code>train_sub</code> dataset which will be used for model fitting.</p>

<div class="highlight highlight-r"><pre><span class="pl-smi">train_sub</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">training</span>[, <span class="pl-k">!</span><span class="pl-smi">nzv</span><span class="pl-k">$</span><span class="pl-smi">zeroVar</span> <span class="pl-k">&amp;</span> 
                        <span class="pl-k">!</span>(names(<span class="pl-smi">training</span>) <span class="pl-k">%in%</span> c(<span class="pl-s"><span class="pl-pds">"</span>X<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>user_name<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>cvtd_timestamp<span class="pl-pds">"</span></span>,
                                                <span class="pl-s"><span class="pl-pds">"</span>new_window<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>raw_timestamp_part_1<span class="pl-pds">"</span></span>,
                                                <span class="pl-s"><span class="pl-pds">"</span>raw_timestamp_part_2<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>num_window<span class="pl-pds">"</span></span>))]
<span class="pl-smi">train_sub</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">train_sub</span>[, <span class="pl-k">!</span>sapply(<span class="pl-smi">train_sub</span>, <span class="pl-k">function</span>(<span class="pl-smi">x</span>) any(is.na(<span class="pl-smi">x</span>)))]
str(<span class="pl-smi">train_sub</span>)</pre></div>

<pre><code>## 'data.frame':    11776 obs. of  53 variables:
##  $ roll_belt           : num  1.41 1.41 1.42 1.48 1.48 1.45 1.45 1.45 1.43 1.42 ...
##  $ pitch_belt          : num  8.07 8.07 8.07 8.05 8.07 8.06 8.17 8.18 8.18 8.2 ...
##  $ yaw_belt            : num  -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 ...
##  $ total_accel_belt    : int  3 3 3 3 3 3 3 3 3 3 ...
##  $ gyros_belt_x        : num  0 0.02 0 0.02 0.02 0.02 0.03 0.03 0.02 0.02 ...
##  $ gyros_belt_y        : num  0 0 0 0 0.02 0 0 0 0 0 ...
##  $ gyros_belt_z        : num  -0.02 -0.02 -0.02 -0.03 -0.02 -0.02 0 -0.02 -0.02 0 ...
##  $ accel_belt_x        : int  -21 -22 -20 -22 -21 -21 -21 -21 -22 -22 ...
##  $ accel_belt_y        : int  4 4 5 3 2 4 4 2 2 4 ...
##  $ accel_belt_z        : int  22 22 23 21 24 21 22 23 23 21 ...
##  $ magnet_belt_x       : int  -3 -7 -2 -6 -6 0 -3 -5 -2 -3 ...
##  $ magnet_belt_y       : int  599 608 600 604 600 603 609 596 602 606 ...
##  $ magnet_belt_z       : int  -313 -311 -305 -310 -302 -312 -308 -317 -319 -309 ...
##  $ roll_arm            : num  -128 -128 -128 -128 -128 -128 -128 -128 -128 -128 ...
##  $ pitch_arm           : num  22.5 22.5 22.5 22.1 22.1 22 21.6 21.5 21.5 21.4 ...
##  $ yaw_arm             : num  -161 -161 -161 -161 -161 -161 -161 -161 -161 -161 ...
##  $ total_accel_arm     : int  34 34 34 34 34 34 34 34 34 34 ...
##  $ gyros_arm_x         : num  0 0.02 0.02 0.02 0 0.02 0.02 0.02 0.02 0.02 ...
##  $ gyros_arm_y         : num  0 -0.02 -0.02 -0.03 -0.03 -0.03 -0.03 -0.03 -0.03 -0.02 ...
##  $ gyros_arm_z         : num  -0.02 -0.02 -0.02 0.02 0 0 -0.02 0 0 -0.02 ...
##  $ accel_arm_x         : int  -288 -290 -289 -289 -289 -289 -288 -290 -288 -287 ...
##  $ accel_arm_y         : int  109 110 110 111 111 111 110 110 111 111 ...
##  $ accel_arm_z         : int  -123 -125 -126 -123 -123 -122 -124 -123 -123 -124 ...
##  $ magnet_arm_x        : int  -368 -369 -368 -372 -374 -369 -376 -366 -363 -372 ...
##  $ magnet_arm_y        : int  337 337 344 344 337 342 334 339 343 338 ...
##  $ magnet_arm_z        : int  516 513 513 512 506 513 516 509 520 509 ...
##  $ roll_dumbbell       : num  13.1 13.1 12.9 13.4 13.4 ...
##  $ pitch_dumbbell      : num  -70.5 -70.6 -70.3 -70.4 -70.4 ...
##  $ yaw_dumbbell        : num  -84.9 -84.7 -85.1 -84.9 -84.9 ...
##  $ total_accel_dumbbell: int  37 37 37 37 37 37 37 37 37 37 ...
##  $ gyros_dumbbell_x    : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ gyros_dumbbell_y    : num  -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 ...
##  $ gyros_dumbbell_z    : num  0 0 0 -0.02 0 0 0 0 0 -0.02 ...
##  $ accel_dumbbell_x    : int  -234 -233 -232 -232 -233 -234 -235 -233 -233 -234 ...
##  $ accel_dumbbell_y    : int  47 47 46 48 48 48 48 47 47 48 ...
##  $ accel_dumbbell_z    : int  -271 -269 -270 -269 -270 -269 -270 -269 -270 -269 ...
##  $ magnet_dumbbell_x   : int  -559 -555 -561 -552 -554 -558 -558 -564 -554 -552 ...
##  $ magnet_dumbbell_y   : int  293 296 298 303 292 294 291 299 291 302 ...
##  $ magnet_dumbbell_z   : num  -65 -64 -63 -60 -68 -66 -69 -64 -65 -69 ...
##  $ roll_forearm        : num  28.4 28.3 28.3 28.1 28 27.9 27.7 27.6 27.5 27.2 ...
##  $ pitch_forearm       : num  -63.9 -63.9 -63.9 -63.9 -63.9 -63.9 -63.8 -63.8 -63.8 -63.9 ...
##  $ yaw_forearm         : num  -153 -153 -152 -152 -152 -152 -152 -152 -152 -151 ...
##  $ total_accel_forearm : int  36 36 36 36 36 36 36 36 36 36 ...
##  $ gyros_forearm_x     : num  0.03 0.02 0.03 0.02 0.02 0.02 0.02 0.02 0.02 0 ...
##  $ gyros_forearm_y     : num  0 0 -0.02 -0.02 0 -0.02 0 -0.02 0.02 0 ...
##  $ gyros_forearm_z     : num  -0.02 -0.02 0 0 -0.02 -0.03 -0.02 -0.02 -0.03 -0.03 ...
##  $ accel_forearm_x     : int  192 192 196 189 189 193 190 193 191 193 ...
##  $ accel_forearm_y     : int  203 203 204 206 206 203 205 205 203 205 ...
##  $ accel_forearm_z     : int  -215 -216 -213 -214 -214 -215 -215 -214 -215 -215 ...
##  $ magnet_forearm_x    : int  -17 -18 -18 -16 -17 -9 -22 -17 -11 -15 ...
##  $ magnet_forearm_y    : num  654 661 658 658 655 660 656 657 657 655 ...
##  $ magnet_forearm_z    : num  476 473 469 469 473 478 473 465 478 472 ...
##  $ classe              : Factor w/ 5 levels "A","B","C","D",..: 1 1 1 1 1 1 1 1 1 1 ...
</code></pre>

<h2>
<a id="model-fitting" class="anchor" href="#model-fitting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model Fitting</h2>

<p>Random Forest is the model of choice. However, when training the model, we run into <em>performance issues</em>: The time requirement of the model fitting procedure for all of the 11776 observations in the training dataset is too high. Hence, we resample the train dataset to contain only about 1000 observations.</p>

<p>However, this gives us the chance to compare several classification algorithms on a (relatively large) validation dataset:</p>

<ol>
<li>
<code>train_small</code> contains 10% of the observations of the training set created above</li>
<li>
<code>validation</code> contains 90% of the observations of the training set created above</li>
</ol>

<div class="highlight highlight-r"><pre>set.seed(<span class="pl-c1">7824</span>)
<span class="pl-smi">train_small_idx</span> <span class="pl-k">&lt;-</span> createDataPartition(<span class="pl-smi">train_sub</span><span class="pl-k">$</span><span class="pl-smi">classe</span>, <span class="pl-v">p</span> <span class="pl-k">=</span> .<span class="pl-c1">1</span>, <span class="pl-v">list</span> <span class="pl-k">=</span> <span class="pl-c1">FALSE</span>)
<span class="pl-smi">train_small</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">train_sub</span>[<span class="pl-smi">train_small_idx</span>, ]
<span class="pl-smi">validation</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">train_sub</span>[<span class="pl-k">-</span><span class="pl-smi">train_small_idx</span>, ]
nrow(<span class="pl-smi">train_small</span>)</pre></div>

<pre><code>## [1] 1179
</code></pre>

<p><em>Cross Validation</em> is applied to choose the model tuning parameters (<code>mtry</code>, i.e. the number of variables to consider on each split in the random forest model). The cross validated accuracy is a measure of the expected accuracy on new observations.</p>

<div class="highlight highlight-r"><pre>set.seed(<span class="pl-c1">3377</span>)
<span class="pl-smi">rf_fit</span> <span class="pl-k">&lt;-</span> train(<span class="pl-smi">classe</span> <span class="pl-k">~</span> ., <span class="pl-smi">train_small</span>, 
                <span class="pl-v">method</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>rf<span class="pl-pds">"</span></span>,
                <span class="pl-v">tuneLength</span> <span class="pl-k">=</span> <span class="pl-c1">5</span>,
                <span class="pl-v">trControl</span> <span class="pl-k">=</span> trainControl(<span class="pl-v">method</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>cv<span class="pl-pds">"</span></span>))
<span class="pl-smi">rf_fit</span></pre></div>

<pre><code>## Random Forest 
## 
## 1179 samples
##   52 predictor
##    5 classes: 'A', 'B', 'C', 'D', 'E' 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 1060, 1060, 1062, 1063, 1060, 1063, ... 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa      Accuracy SD  Kappa SD  
##    2    0.9008154  0.8743579  0.03344033   0.04253098
##   14    0.9126090  0.8893842  0.03153210   0.03990121
##   27    0.9049233  0.8796691  0.03853582   0.04874757
##   39    0.9007218  0.8743122  0.03638930   0.04605251
##   52    0.8939048  0.8657369  0.03422046   0.04329525
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 14.
</code></pre>

<div class="highlight highlight-r"><pre>plot(varImp(<span class="pl-smi">rf_fit</span>))</pre></div>

<p><img src="figure/modelFitting-1.png" alt="plot of chunk modelFitting"> </p>

<div class="highlight highlight-r"><pre>set.seed(<span class="pl-c1">34671</span>)
<span class="pl-smi">rpart_fit</span> <span class="pl-k">&lt;-</span> train(<span class="pl-smi">classe</span> <span class="pl-k">~</span> ., <span class="pl-smi">train_small</span>, 
                <span class="pl-v">method</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>rpart<span class="pl-pds">"</span></span>,
                <span class="pl-v">tuneLength</span> <span class="pl-k">=</span> <span class="pl-c1">20</span>,
                <span class="pl-v">trControl</span> <span class="pl-k">=</span> trainControl(<span class="pl-v">method</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>cv<span class="pl-pds">"</span></span>))

(<span class="pl-smi">rf_acc</span> <span class="pl-k">&lt;-</span> confusionMatrix(predict(<span class="pl-smi">rf_fit</span>, <span class="pl-smi">validation</span>), <span class="pl-smi">validation</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)<span class="pl-k">$</span><span class="pl-smi">overall</span>[<span class="pl-s"><span class="pl-pds">"</span>Accuracy<span class="pl-pds">"</span></span>])</pre></div>

<pre><code>##  Accuracy 
## 0.9269605
</code></pre>

<div class="highlight highlight-r"><pre>(<span class="pl-smi">rpart_acc</span> <span class="pl-k">&lt;-</span> confusionMatrix(predict(<span class="pl-smi">rpart_fit</span>, <span class="pl-smi">validation</span>), <span class="pl-smi">validation</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)<span class="pl-k">$</span><span class="pl-smi">overall</span>[<span class="pl-s"><span class="pl-pds">"</span>Accuracy<span class="pl-pds">"</span></span>])</pre></div>

<pre><code>## Accuracy 
## 0.734925
</code></pre>

<p>The Random Forest performs much better on the validation set than the CART classification tree (92.7% vs. 73.49% accuracy) </p>

<h2>
<a id="model-evaluation" class="anchor" href="#model-evaluation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model Evaluation</h2>

<p>The random forest is tested on the hold out observations in the testset. The accuracy on the testset is the final measure of accuracy on out of sample observations. The same preprocessing as for the trainingset has to be applied to the testset. The following preprocessing steps have been performed:</p>

<ul>
<li>transform factors</li>
<li>drop variables</li>
</ul>

<p>We do not need to drop variables on the testset explicitly. Instead, the model will simply ignore those variables when calculating predictions.</p>

<div class="highlight highlight-r"><pre><span class="pl-smi">testing</span> <span class="pl-k">&lt;-</span> transformFactors(<span class="pl-smi">testing</span>)
confusionMatrix(predict(<span class="pl-smi">rf_fit</span>, <span class="pl-smi">testing</span>), <span class="pl-smi">testing</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)</pre></div>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2198  110    1   16    4
##          B   10 1277   82    2   44
##          C   15  113 1247   67   34
##          D    8   11   26 1183   29
##          E    1    7   12   18 1331
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9223          
##                  95% CI : (0.9161, 0.9281)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9015          
##  Mcnemar's Test P-Value : &lt; 2.2e-16       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9848   0.8412   0.9115   0.9199   0.9230
## Specificity            0.9767   0.9782   0.9646   0.9887   0.9941
## Pos Pred Value         0.9438   0.9025   0.8449   0.9411   0.9722
## Neg Pred Value         0.9938   0.9625   0.9810   0.9844   0.9829
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2801   0.1628   0.1589   0.1508   0.1696
## Detection Prevalence   0.2968   0.1803   0.1881   0.1602   0.1745
## Balanced Accuracy      0.9807   0.9097   0.9381   0.9543   0.9585
</code></pre>

<p>Predictions for the <code>pml_test</code> dataset (required for submission and automated scoring) can be obtained as follows:</p>

<div class="highlight highlight-r"><pre><span class="pl-smi">pml_test</span> <span class="pl-k">&lt;-</span> transformFactors(<span class="pl-smi">pml_test</span>)
<span class="pl-smi">submission</span> <span class="pl-k">&lt;-</span> predict(<span class="pl-smi">rf_fit</span>, <span class="pl-smi">pml_test</span>)
<span class="pl-smi">submission</span></pre></div>

<pre><code>##  [1] C A A A A E D D A A B C B A E E A B B B
## Levels: A B C D E
</code></pre>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/zaep/courseraPML">courserapml</a> is maintained by <a href="https://github.com/zaep">zaep</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>

