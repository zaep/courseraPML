{"name":"courserapml","tagline":"","body":"## Loading the data\r\n\r\nThe following code loads the training and testing datasets into R:\r\n\r\n```r\r\npml_train <- read.csv(\"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\")\r\npml_test <- read.csv(\"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\")\r\n```\r\n\r\n\r\n## Splitting the data\r\n\r\nWe set a seed value to make the data partitioning reproducible.\r\n\r\n\r\n```r\r\nstr(pml_train)\r\n```\r\n\r\n```\r\n## 'data.frame':\t19622 obs. of  160 variables:\r\n##  $ X                       : int  1 2 3 4 5 6 7 8 9 10 ...\r\n##  $ user_name               : Factor w/ 6 levels \"adelmo\",\"carlitos\",..: 2 2 2 2 2 2 2 2 2 2 ...\r\n##  $ raw_timestamp_part_1    : int  1323084231 1323084231 1323084231 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 ...\r\n##  $ raw_timestamp_part_2    : int  788290 808298 820366 120339 196328 304277 368296 440390 484323 484434 ...\r\n##  $ cvtd_timestamp          : Factor w/ 20 levels \"02/12/2011 13:32\",..: 9 9 9 9 9 9 9 9 9 9 ...\r\n##  $ new_window              : Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ num_window              : int  11 11 11 12 12 12 12 12 12 12 ...\r\n##  $ roll_belt               : num  1.41 1.41 1.42 1.48 1.48 1.45 1.42 1.42 1.43 1.45 ...\r\n##  $ pitch_belt              : num  8.07 8.07 8.07 8.05 8.07 8.06 8.09 8.13 8.16 8.17 ...\r\n##  $ yaw_belt                : num  -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 ...\r\n##  $ total_accel_belt        : int  3 3 3 3 3 3 3 3 3 3 ...\r\n##  $ kurtosis_roll_belt      : Factor w/ 397 levels \"\",\"-0.016850\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_picth_belt     : Factor w/ 317 levels \"\",\"-0.021887\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_yaw_belt       : Factor w/ 2 levels \"\",\"#DIV/0!\": 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_roll_belt      : Factor w/ 395 levels \"\",\"-0.003095\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_roll_belt.1    : Factor w/ 338 levels \"\",\"-0.005928\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_yaw_belt       : Factor w/ 2 levels \"\",\"#DIV/0!\": 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ max_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ max_picth_belt          : int  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ max_yaw_belt            : Factor w/ 68 levels \"\",\"-0.1\",\"-0.2\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ min_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ min_pitch_belt          : int  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ min_yaw_belt            : Factor w/ 68 levels \"\",\"-0.1\",\"-0.2\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ amplitude_roll_belt     : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ amplitude_pitch_belt    : int  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ amplitude_yaw_belt      : Factor w/ 4 levels \"\",\"#DIV/0!\",\"0.00\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ var_total_accel_belt    : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ avg_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ stddev_roll_belt        : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ var_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ avg_pitch_belt          : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ stddev_pitch_belt       : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ var_pitch_belt          : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ avg_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ stddev_yaw_belt         : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ var_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ gyros_belt_x            : num  0 0.02 0 0.02 0.02 0.02 0.02 0.02 0.02 0.03 ...\r\n##  $ gyros_belt_y            : num  0 0 0 0 0.02 0 0 0 0 0 ...\r\n##  $ gyros_belt_z            : num  -0.02 -0.02 -0.02 -0.03 -0.02 -0.02 -0.02 -0.02 -0.02 0 ...\r\n##  $ accel_belt_x            : int  -21 -22 -20 -22 -21 -21 -22 -22 -20 -21 ...\r\n##  $ accel_belt_y            : int  4 4 5 3 2 4 3 4 2 4 ...\r\n##  $ accel_belt_z            : int  22 22 23 21 24 21 21 21 24 22 ...\r\n##  $ magnet_belt_x           : int  -3 -7 -2 -6 -6 0 -4 -2 1 -3 ...\r\n##  $ magnet_belt_y           : int  599 608 600 604 600 603 599 603 602 609 ...\r\n##  $ magnet_belt_z           : int  -313 -311 -305 -310 -302 -312 -311 -313 -312 -308 ...\r\n##  $ roll_arm                : num  -128 -128 -128 -128 -128 -128 -128 -128 -128 -128 ...\r\n##  $ pitch_arm               : num  22.5 22.5 22.5 22.1 22.1 22 21.9 21.8 21.7 21.6 ...\r\n##  $ yaw_arm                 : num  -161 -161 -161 -161 -161 -161 -161 -161 -161 -161 ...\r\n##  $ total_accel_arm         : int  34 34 34 34 34 34 34 34 34 34 ...\r\n##  $ var_accel_arm           : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ avg_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ stddev_roll_arm         : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ var_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ avg_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ stddev_pitch_arm        : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ var_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ avg_yaw_arm             : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ stddev_yaw_arm          : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ var_yaw_arm             : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ gyros_arm_x             : num  0 0.02 0.02 0.02 0 0.02 0 0.02 0.02 0.02 ...\r\n##  $ gyros_arm_y             : num  0 -0.02 -0.02 -0.03 -0.03 -0.03 -0.03 -0.02 -0.03 -0.03 ...\r\n##  $ gyros_arm_z             : num  -0.02 -0.02 -0.02 0.02 0 0 0 0 -0.02 -0.02 ...\r\n##  $ accel_arm_x             : int  -288 -290 -289 -289 -289 -289 -289 -289 -288 -288 ...\r\n##  $ accel_arm_y             : int  109 110 110 111 111 111 111 111 109 110 ...\r\n##  $ accel_arm_z             : int  -123 -125 -126 -123 -123 -122 -125 -124 -122 -124 ...\r\n##  $ magnet_arm_x            : int  -368 -369 -368 -372 -374 -369 -373 -372 -369 -376 ...\r\n##  $ magnet_arm_y            : int  337 337 344 344 337 342 336 338 341 334 ...\r\n##  $ magnet_arm_z            : int  516 513 513 512 506 513 509 510 518 516 ...\r\n##  $ kurtosis_roll_arm       : Factor w/ 330 levels \"\",\"-0.02438\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_picth_arm      : Factor w/ 328 levels \"\",\"-0.00484\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_yaw_arm        : Factor w/ 395 levels \"\",\"-0.01548\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_roll_arm       : Factor w/ 331 levels \"\",\"-0.00051\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_pitch_arm      : Factor w/ 328 levels \"\",\"-0.00184\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_yaw_arm        : Factor w/ 395 levels \"\",\"-0.00311\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ max_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ max_picth_arm           : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ max_yaw_arm             : int  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ min_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ min_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ min_yaw_arm             : int  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ amplitude_roll_arm      : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ amplitude_pitch_arm     : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ amplitude_yaw_arm       : int  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ roll_dumbbell           : num  13.1 13.1 12.9 13.4 13.4 ...\r\n##  $ pitch_dumbbell          : num  -70.5 -70.6 -70.3 -70.4 -70.4 ...\r\n##  $ yaw_dumbbell            : num  -84.9 -84.7 -85.1 -84.9 -84.9 ...\r\n##  $ kurtosis_roll_dumbbell  : Factor w/ 398 levels \"\",\"-0.0035\",\"-0.0073\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_picth_dumbbell : Factor w/ 401 levels \"\",\"-0.0163\",\"-0.0233\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_yaw_dumbbell   : Factor w/ 2 levels \"\",\"#DIV/0!\": 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_roll_dumbbell  : Factor w/ 401 levels \"\",\"-0.0082\",\"-0.0096\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_pitch_dumbbell : Factor w/ 402 levels \"\",\"-0.0053\",\"-0.0084\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_yaw_dumbbell   : Factor w/ 2 levels \"\",\"#DIV/0!\": 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ max_roll_dumbbell       : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ max_picth_dumbbell      : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ max_yaw_dumbbell        : Factor w/ 73 levels \"\",\"-0.1\",\"-0.2\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ min_roll_dumbbell       : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ min_pitch_dumbbell      : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##  $ min_yaw_dumbbell        : Factor w/ 73 levels \"\",\"-0.1\",\"-0.2\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ amplitude_roll_dumbbell : num  NA NA NA NA NA NA NA NA NA NA ...\r\n##   [list output truncated]\r\n```\r\n\r\n```r\r\nlibrary(caret)\r\n\r\nset.seed(126377)\r\ntrain_idx <- createDataPartition(pml_train$classe, p = .6, list = FALSE)\r\n\r\ntraining <- pml_train[train_idx, ]\r\ntesting <- pml_train[-train_idx, ]\r\n```\r\n\r\n\r\n## Exploratory Data Analysis\r\n\r\n\r\n\r\n```r\r\nstr(training[, sapply(training, is.factor)])\r\n```\r\n\r\n```\r\n## 'data.frame':\t11776 obs. of  37 variables:\r\n##  $ user_name              : Factor w/ 6 levels \"adelmo\",\"carlitos\",..: 2 2 2 2 2 2 2 2 2 2 ...\r\n##  $ cvtd_timestamp         : Factor w/ 20 levels \"02/12/2011 13:32\",..: 9 9 9 9 9 9 9 9 9 9 ...\r\n##  $ new_window             : Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_roll_belt     : Factor w/ 397 levels \"\",\"-0.016850\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_picth_belt    : Factor w/ 317 levels \"\",\"-0.021887\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_yaw_belt      : Factor w/ 2 levels \"\",\"#DIV/0!\": 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_roll_belt     : Factor w/ 395 levels \"\",\"-0.003095\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_roll_belt.1   : Factor w/ 338 levels \"\",\"-0.005928\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_yaw_belt      : Factor w/ 2 levels \"\",\"#DIV/0!\": 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ max_yaw_belt           : Factor w/ 68 levels \"\",\"-0.1\",\"-0.2\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ min_yaw_belt           : Factor w/ 68 levels \"\",\"-0.1\",\"-0.2\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ amplitude_yaw_belt     : Factor w/ 4 levels \"\",\"#DIV/0!\",\"0.00\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_roll_arm      : Factor w/ 330 levels \"\",\"-0.02438\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_picth_arm     : Factor w/ 328 levels \"\",\"-0.00484\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_yaw_arm       : Factor w/ 395 levels \"\",\"-0.01548\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_roll_arm      : Factor w/ 331 levels \"\",\"-0.00051\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_pitch_arm     : Factor w/ 328 levels \"\",\"-0.00184\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_yaw_arm       : Factor w/ 395 levels \"\",\"-0.00311\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_roll_dumbbell : Factor w/ 398 levels \"\",\"-0.0035\",\"-0.0073\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_picth_dumbbell: Factor w/ 401 levels \"\",\"-0.0163\",\"-0.0233\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_yaw_dumbbell  : Factor w/ 2 levels \"\",\"#DIV/0!\": 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_roll_dumbbell : Factor w/ 401 levels \"\",\"-0.0082\",\"-0.0096\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_pitch_dumbbell: Factor w/ 402 levels \"\",\"-0.0053\",\"-0.0084\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_yaw_dumbbell  : Factor w/ 2 levels \"\",\"#DIV/0!\": 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ max_yaw_dumbbell       : Factor w/ 73 levels \"\",\"-0.1\",\"-0.2\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ min_yaw_dumbbell       : Factor w/ 73 levels \"\",\"-0.1\",\"-0.2\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ amplitude_yaw_dumbbell : Factor w/ 3 levels \"\",\"#DIV/0!\",\"0.00\": 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_roll_forearm  : Factor w/ 322 levels \"\",\"-0.0227\",\"-0.0359\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_picth_forearm : Factor w/ 323 levels \"\",\"-0.0073\",\"-0.0442\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ kurtosis_yaw_forearm   : Factor w/ 2 levels \"\",\"#DIV/0!\": 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_roll_forearm  : Factor w/ 323 levels \"\",\"-0.0004\",\"-0.0013\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_pitch_forearm : Factor w/ 319 levels \"\",\"-0.0113\",\"-0.0131\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ skewness_yaw_forearm   : Factor w/ 2 levels \"\",\"#DIV/0!\": 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ max_yaw_forearm        : Factor w/ 45 levels \"\",\"-0.1\",\"-0.2\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ min_yaw_forearm        : Factor w/ 45 levels \"\",\"-0.1\",\"-0.2\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ amplitude_yaw_forearm  : Factor w/ 3 levels \"\",\"#DIV/0!\",\"0.00\": 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ classe                 : Factor w/ 5 levels \"A\",\"B\",\"C\",\"D\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n```\r\n\r\nThere are several factor variables in the dataset. However, it seems like some of them should really be numeric, since they have many levels. Some algorithms can not handle factors with more than 32 levels (e.g. `tree::tree()`). Hence, all factor variables with more than 32 levels are transformed into numerical variables. In addition, the `user_name` variable should be a character variable (although there are only 6 user names in the training set, the set of all possible user names might be large), while `cvtd_timestamp` should be a datetime format.\r\n\r\nWe create a function for factor transformation, so the same transformations can later be easily applied to the test dataset.\r\n\r\n\r\n```r\r\ntransformFactors <- function(data) {\r\n  cols <- sapply(data, is.factor) & grepl(\"skewness|kurtosis|yaw\", names(data))\r\n  data[, cols] <- as.numeric(as.character(data[, cols]))\r\n  data$user_name <- as.character(data$user_name)\r\n  data$cvtd_timestamp <- lubridate::parse_date_time(data$cvtd_timestamp, \"d/m/Y H:M\")\r\n  return(data)\r\n}\r\n\r\ntraining <- transformFactors(training)\r\n```\r\n\r\n```\r\n## Warning in transformFactors(training): NAs introduced by coercion\r\n```\r\n\r\n```r\r\nstr(training[, sapply(training, is.factor)])\r\n```\r\n\r\n```\r\n## 'data.frame':\t11776 obs. of  2 variables:\r\n##  $ new_window: Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 1 1 1 1 1 1 ...\r\n##  $ classe    : Factor w/ 5 levels \"A\",\"B\",\"C\",\"D\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n```\r\n\r\nIn order to visualize the dataset in two dimensional space, we perform _Principal Component Analysis_ (PCA). Before PCA can be applied, we need to:\r\n\r\n- Remove variables with zero variance (`caret::nearZeroVar` is used to identify such variables)\r\n- Remove non-numerical variables\r\n- Center and Scale variables\r\n\r\nThe first two principal components capture most of the variance in the dataset.\r\n\r\n\r\n```r\r\n# identify zero variance variables\r\nnzv <- nearZeroVar(training, saveMetrics = TRUE)\r\n#remove zero variance and non-numeric variables\r\ntrain_num <- training[, !nzv$zeroVar & sapply(training, is.numeric)]\r\n# scale and center, then perform PCA\r\npca_train <- prcomp(train_num[complete.cases(train_num), -1],\r\n                     center = TRUE,\r\n                     scale. = TRUE)\r\nplot(pca_train)\r\n```\r\n\r\n![plot of chunk edaPCA](figure/edaPCA-1.png) \r\n\r\nNext, we plot the first two principal components and use the `classe` variable to color the observations. The plot indicates that the observations fall into 3-4 clusters. However, those cluster do not separate the `classe` variable values very well.\r\n\r\n\r\n```r\r\nlibrary(ggplot2)\r\nlibrary(scales)\r\n\r\nidxs <- train_num[complete.cases(train_num), \"X\"]\r\n\r\nggplot(data.frame(pc1 = pca_train$x[, 1], \r\n                  pc2 = pca_train$x[, 2], \r\n                  classe = training[training$X %in% idxs, \"classe\"]), \r\n       aes(pc1, pc2)) + \r\n  geom_point(aes(color = classe), size = 3) +\r\n  ggtitle(\"First 2 principal components of the WLE dataset\")\r\n```\r\n\r\n![plot of chunk edaPCAPlot](figure/edaPCAPlot-1.png) \r\n\r\n## Data Preprocessing\r\nWe remove variables which\r\n\r\n- have 0 variance\r\n- have `NA` values in it\r\n- identify individual rows (index variable `X`) or study participants (`user_name`), \r\n- are timestamps (`cvtd_timestamp`, `raw_timestamp_part_1`, `raw_timestamp_part_2`), \r\n- and time window indicators (`num_window`, `new_window`).\r\n\r\nThis gives us the `train_sub` dataset which will be used for model fitting.\r\n\r\n\r\n```r\r\ntrain_sub <- training[, !nzv$zeroVar & \r\n                        !(names(training) %in% c(\"X\", \"user_name\", \"cvtd_timestamp\",\r\n                                                \"new_window\", \"raw_timestamp_part_1\",\r\n                                                \"raw_timestamp_part_2\", \"num_window\"))]\r\ntrain_sub <- train_sub[, !sapply(train_sub, function(x) any(is.na(x)))]\r\nstr(train_sub)\r\n```\r\n\r\n```\r\n## 'data.frame':\t11776 obs. of  53 variables:\r\n##  $ roll_belt           : num  1.41 1.41 1.42 1.48 1.48 1.45 1.45 1.45 1.43 1.42 ...\r\n##  $ pitch_belt          : num  8.07 8.07 8.07 8.05 8.07 8.06 8.17 8.18 8.18 8.2 ...\r\n##  $ yaw_belt            : num  -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 ...\r\n##  $ total_accel_belt    : int  3 3 3 3 3 3 3 3 3 3 ...\r\n##  $ gyros_belt_x        : num  0 0.02 0 0.02 0.02 0.02 0.03 0.03 0.02 0.02 ...\r\n##  $ gyros_belt_y        : num  0 0 0 0 0.02 0 0 0 0 0 ...\r\n##  $ gyros_belt_z        : num  -0.02 -0.02 -0.02 -0.03 -0.02 -0.02 0 -0.02 -0.02 0 ...\r\n##  $ accel_belt_x        : int  -21 -22 -20 -22 -21 -21 -21 -21 -22 -22 ...\r\n##  $ accel_belt_y        : int  4 4 5 3 2 4 4 2 2 4 ...\r\n##  $ accel_belt_z        : int  22 22 23 21 24 21 22 23 23 21 ...\r\n##  $ magnet_belt_x       : int  -3 -7 -2 -6 -6 0 -3 -5 -2 -3 ...\r\n##  $ magnet_belt_y       : int  599 608 600 604 600 603 609 596 602 606 ...\r\n##  $ magnet_belt_z       : int  -313 -311 -305 -310 -302 -312 -308 -317 -319 -309 ...\r\n##  $ roll_arm            : num  -128 -128 -128 -128 -128 -128 -128 -128 -128 -128 ...\r\n##  $ pitch_arm           : num  22.5 22.5 22.5 22.1 22.1 22 21.6 21.5 21.5 21.4 ...\r\n##  $ yaw_arm             : num  -161 -161 -161 -161 -161 -161 -161 -161 -161 -161 ...\r\n##  $ total_accel_arm     : int  34 34 34 34 34 34 34 34 34 34 ...\r\n##  $ gyros_arm_x         : num  0 0.02 0.02 0.02 0 0.02 0.02 0.02 0.02 0.02 ...\r\n##  $ gyros_arm_y         : num  0 -0.02 -0.02 -0.03 -0.03 -0.03 -0.03 -0.03 -0.03 -0.02 ...\r\n##  $ gyros_arm_z         : num  -0.02 -0.02 -0.02 0.02 0 0 -0.02 0 0 -0.02 ...\r\n##  $ accel_arm_x         : int  -288 -290 -289 -289 -289 -289 -288 -290 -288 -287 ...\r\n##  $ accel_arm_y         : int  109 110 110 111 111 111 110 110 111 111 ...\r\n##  $ accel_arm_z         : int  -123 -125 -126 -123 -123 -122 -124 -123 -123 -124 ...\r\n##  $ magnet_arm_x        : int  -368 -369 -368 -372 -374 -369 -376 -366 -363 -372 ...\r\n##  $ magnet_arm_y        : int  337 337 344 344 337 342 334 339 343 338 ...\r\n##  $ magnet_arm_z        : int  516 513 513 512 506 513 516 509 520 509 ...\r\n##  $ roll_dumbbell       : num  13.1 13.1 12.9 13.4 13.4 ...\r\n##  $ pitch_dumbbell      : num  -70.5 -70.6 -70.3 -70.4 -70.4 ...\r\n##  $ yaw_dumbbell        : num  -84.9 -84.7 -85.1 -84.9 -84.9 ...\r\n##  $ total_accel_dumbbell: int  37 37 37 37 37 37 37 37 37 37 ...\r\n##  $ gyros_dumbbell_x    : num  0 0 0 0 0 0 0 0 0 0 ...\r\n##  $ gyros_dumbbell_y    : num  -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 ...\r\n##  $ gyros_dumbbell_z    : num  0 0 0 -0.02 0 0 0 0 0 -0.02 ...\r\n##  $ accel_dumbbell_x    : int  -234 -233 -232 -232 -233 -234 -235 -233 -233 -234 ...\r\n##  $ accel_dumbbell_y    : int  47 47 46 48 48 48 48 47 47 48 ...\r\n##  $ accel_dumbbell_z    : int  -271 -269 -270 -269 -270 -269 -270 -269 -270 -269 ...\r\n##  $ magnet_dumbbell_x   : int  -559 -555 -561 -552 -554 -558 -558 -564 -554 -552 ...\r\n##  $ magnet_dumbbell_y   : int  293 296 298 303 292 294 291 299 291 302 ...\r\n##  $ magnet_dumbbell_z   : num  -65 -64 -63 -60 -68 -66 -69 -64 -65 -69 ...\r\n##  $ roll_forearm        : num  28.4 28.3 28.3 28.1 28 27.9 27.7 27.6 27.5 27.2 ...\r\n##  $ pitch_forearm       : num  -63.9 -63.9 -63.9 -63.9 -63.9 -63.9 -63.8 -63.8 -63.8 -63.9 ...\r\n##  $ yaw_forearm         : num  -153 -153 -152 -152 -152 -152 -152 -152 -152 -151 ...\r\n##  $ total_accel_forearm : int  36 36 36 36 36 36 36 36 36 36 ...\r\n##  $ gyros_forearm_x     : num  0.03 0.02 0.03 0.02 0.02 0.02 0.02 0.02 0.02 0 ...\r\n##  $ gyros_forearm_y     : num  0 0 -0.02 -0.02 0 -0.02 0 -0.02 0.02 0 ...\r\n##  $ gyros_forearm_z     : num  -0.02 -0.02 0 0 -0.02 -0.03 -0.02 -0.02 -0.03 -0.03 ...\r\n##  $ accel_forearm_x     : int  192 192 196 189 189 193 190 193 191 193 ...\r\n##  $ accel_forearm_y     : int  203 203 204 206 206 203 205 205 203 205 ...\r\n##  $ accel_forearm_z     : int  -215 -216 -213 -214 -214 -215 -215 -214 -215 -215 ...\r\n##  $ magnet_forearm_x    : int  -17 -18 -18 -16 -17 -9 -22 -17 -11 -15 ...\r\n##  $ magnet_forearm_y    : num  654 661 658 658 655 660 656 657 657 655 ...\r\n##  $ magnet_forearm_z    : num  476 473 469 469 473 478 473 465 478 472 ...\r\n##  $ classe              : Factor w/ 5 levels \"A\",\"B\",\"C\",\"D\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n```\r\n\r\n\r\n## Model Fitting\r\n\r\nRandom Forest is the model of choice. However, when training the model, we run into _performance issues_: The time requirement of the model fitting procedure for all of the 11776 observations in the training dataset is too high. Hence, we resample the train dataset to contain only about 1000 observations.\r\n\r\nHowever, this gives us the chance to compare several classification algorithms on a (relatively large) validation dataset:\r\n\r\n1. `train_small` contains 10% of the observations of the training set created above\r\n2. `validation` contains 90% of the observations of the training set created above\r\n\r\n\r\n\r\n```r\r\nset.seed(7824)\r\ntrain_small_idx <- createDataPartition(train_sub$classe, p = .1, list = FALSE)\r\ntrain_small <- train_sub[train_small_idx, ]\r\nvalidation <- train_sub[-train_small_idx, ]\r\nnrow(train_small)\r\n```\r\n\r\n```\r\n## [1] 1179\r\n```\r\n\r\n_Cross Validation_ is applied to choose the model tuning parameters (`mtry`, i.e. the number of variables to consider on each split in the random forest model). The cross validated accuracy is a measure of the expected accuracy on new observations.\r\n\r\n\r\n```r\r\nset.seed(3377)\r\nrf_fit <- train(classe ~ ., train_small, \r\n                method = \"rf\",\r\n                tuneLength = 5,\r\n                trControl = trainControl(method = \"cv\"))\r\nrf_fit\r\n```\r\n\r\n```\r\n## Random Forest \r\n## \r\n## 1179 samples\r\n##   52 predictor\r\n##    5 classes: 'A', 'B', 'C', 'D', 'E' \r\n## \r\n## No pre-processing\r\n## Resampling: Cross-Validated (10 fold) \r\n## Summary of sample sizes: 1060, 1060, 1062, 1063, 1060, 1063, ... \r\n## Resampling results across tuning parameters:\r\n## \r\n##   mtry  Accuracy   Kappa      Accuracy SD  Kappa SD  \r\n##    2    0.9008154  0.8743579  0.03344033   0.04253098\r\n##   14    0.9126090  0.8893842  0.03153210   0.03990121\r\n##   27    0.9049233  0.8796691  0.03853582   0.04874757\r\n##   39    0.9007218  0.8743122  0.03638930   0.04605251\r\n##   52    0.8939048  0.8657369  0.03422046   0.04329525\r\n## \r\n## Accuracy was used to select the optimal model using  the largest value.\r\n## The final value used for the model was mtry = 14.\r\n```\r\n\r\n```r\r\nplot(varImp(rf_fit))\r\n```\r\n\r\n![plot of chunk modelFitting](figure/modelFitting-1.png) \r\n\r\n```r\r\nset.seed(34671)\r\nrpart_fit <- train(classe ~ ., train_small, \r\n                method = \"rpart\",\r\n                tuneLength = 20,\r\n                trControl = trainControl(method = \"cv\"))\r\n\r\n(rf_acc <- confusionMatrix(predict(rf_fit, validation), validation$classe)$overall[\"Accuracy\"])\r\n```\r\n\r\n```\r\n##  Accuracy \r\n## 0.9269605\r\n```\r\n\r\n```r\r\n(rpart_acc <- confusionMatrix(predict(rpart_fit, validation), validation$classe)$overall[\"Accuracy\"])\r\n```\r\n\r\n```\r\n## Accuracy \r\n## 0.734925\r\n```\r\n\r\nThe Random Forest performs much better on the validation set than the CART classification tree (92.7% vs. 73.49% accuracy) \r\n\r\n## Model Evaluation\r\n\r\nThe random forest is tested on the hold out observations in the testset. The accuracy on the testset is the final measure of accuracy on out of sample observations. The same preprocessing as for the trainingset has to be applied to the testset. The following preprocessing steps have been performed:\r\n\r\n- transform factors\r\n- drop variables\r\n\r\nWe do not need to drop variables on the testset explicitly. Instead, the model will simply ignore those variables when calculating predictions.\r\n\r\n\r\n```r\r\ntesting <- transformFactors(testing)\r\nconfusionMatrix(predict(rf_fit, testing), testing$classe)\r\n```\r\n\r\n```\r\n## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 2198  110    1   16    4\r\n##          B   10 1277   82    2   44\r\n##          C   15  113 1247   67   34\r\n##          D    8   11   26 1183   29\r\n##          E    1    7   12   18 1331\r\n## \r\n## Overall Statistics\r\n##                                           \r\n##                Accuracy : 0.9223          \r\n##                  95% CI : (0.9161, 0.9281)\r\n##     No Information Rate : 0.2845          \r\n##     P-Value [Acc > NIR] : < 2.2e-16       \r\n##                                           \r\n##                   Kappa : 0.9015          \r\n##  Mcnemar's Test P-Value : < 2.2e-16       \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity            0.9848   0.8412   0.9115   0.9199   0.9230\r\n## Specificity            0.9767   0.9782   0.9646   0.9887   0.9941\r\n## Pos Pred Value         0.9438   0.9025   0.8449   0.9411   0.9722\r\n## Neg Pred Value         0.9938   0.9625   0.9810   0.9844   0.9829\r\n## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838\r\n## Detection Rate         0.2801   0.1628   0.1589   0.1508   0.1696\r\n## Detection Prevalence   0.2968   0.1803   0.1881   0.1602   0.1745\r\n## Balanced Accuracy      0.9807   0.9097   0.9381   0.9543   0.9585\r\n```\r\n\r\nPredictions for the `pml_test` dataset (required for submission and automated scoring) can be obtained as follows:\r\n\r\n\r\n```r\r\npml_test <- transformFactors(pml_test)\r\nsubmission <- predict(rf_fit, pml_test)\r\nsubmission\r\n```\r\n\r\n```\r\n##  [1] C A A A A E D D A A B C B A E E A B B B\r\n## Levels: A B C D E\r\n```","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}